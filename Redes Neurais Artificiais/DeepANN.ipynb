{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Nesse tutorial, vamos implementar uma rede neural profunda usando TensorFlow. Partindo da teoria do [tutorial de introdução às redes neurais](https://matheusfacure.github.io/2017/03/05/ann-intro/) e do que ensinei no [tutorial de TensorFlow essencial](https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/), vamos criar uma rede neural para classificar imagens de dígitos escritos à mão. Nesse caso, os dados são imagens em preto e branco\n",
    "de dígitos desenhados. A dimensão da imagem é 28 por 28 pixeis, o que nos dá 784 variáveis. Os nossos alvos ou classes são vetores *one-hot* com zeros em todas as casas menos na do dígito em questão. Por exemplo, o dígito 7 é representado por um vetor de zeros com 1 na oitava casa `[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFyCAYAAAAkvWviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53a4332668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # para computação numérica menos intensiva\n",
    "import os # para criar pastas\n",
    "from matplotlib import pyplot as plt # para mostrar imagens\n",
    "import tensorflow as tf # para redes neurais\n",
    "\n",
    "# criamos uma pasta para colocar os dados\n",
    "if not os.path.exists('tmp'):\n",
    "    os.makedirs('tmp')\n",
    "\n",
    "# baixa os dados na pasta criada \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"tmp/\", one_hot=True) # carrega os dados já formatados\n",
    "\n",
    "# mostra a centésima imagem no set de treino\n",
    "plt.imshow(data.train.images[100].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "plt.title(str(data.train.labels[100])) # vetor one-hot que representa o dígito\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Recapitulando\n",
    "Nós vimos no [tutorial teórico](https://matheusfacure.github.io/2017/03/05/ann-intro/) de redes neurais que um modelo de rede neural artificial pode ser tão simples quanto \n",
    "\n",
    "$$ \\phi(\\phi(\\pmb{X} \\pmb{W_1})\\pmb{W_2}) \\pmb{w} = \\pmb{y} $$\n",
    "\n",
    "Aqui, vamos considerar uma pequena modificação na formulação:\n",
    "\n",
    "$$ \\phi(\\phi(\\pmb{X} \\pmb{W_1} + \\pmb{b_1})\\pmb{W_2} + \\pmb{b_2}) \\pmb{w} + \\pmb{b} = \\pmb{y} $$\n",
    "\n",
    "Essa formulação é menos concisa mas representa o mesmo modelo. Na primeira formulação, precisamos colocar nos dados uma coluna de $\\pmb{1}$ para calcular os diversos $\\pmb{b}$s (relembre isso no [tutorial de regressão linear](https://matheusfacure.github.io/2017/02/15/MQO-formula-analitica/)). Aqui, como cada cada camada tem seu próprio $\\pmb{b}$, é mais conveniente explicitá-los como na segunda formulação. Apenas para irmos nos acostumando com a nomenclatura, lembre-se de que os $\\pmb{b}$s são chamados de intercepto nos modelos lineares, mas nas redes neurais, nos referimos a eles como vieses (*biases*, do inglês).\n",
    "\n",
    "Vamos relembrar o que acontece no modelo definido acima. Em primeiro lugar, nós multiplicamos os dados por uma grande matriz de parâmetros, aos que chamamos pesos (*weight*). Nós então adicionamos os vieses (*bias*) após essa multiplicação de matriz: $\\pmb{X} \\pmb{W_1} + \\pmb{b_1}$. Isso é uma típica transformação linear onde usamos operações de multiplicação e adição. Após essa transformação linear, nós passamos seu resultado por alguma função não linear $\\phi$, como a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks). Isso resultará no output da primeira camada, $\\pmb{X}^*$. Nós podemos tratamos esse output como o input da segunda camada, e aplicamos nele uma nova transformação linear, seguida de alguma não linearidade para obter o output da segunda camada, $\\pmb{X}^{**}$. Podemos repedir isso por quantas camadas quisermos, mas nesse caso, paramos por aqui e passamos $\\pmb{X}^{**}$ como as variáveis de algum modelo linear, como uma regressão logística.\n",
    "\n",
    "Para implementar esse modelo, vamos considerar o código desenvolvido no [tutorial de TensorFlow](https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/) e fazer algumas pequenas alterações. Como ponto de partida, sugiro que você simplesmente copie e cole o código de lá.\n",
    "\n",
    "## Fase de Construção do Grafo\n",
    "Novamente, começamos definindo algumas constantes, dentre elas, os hiper-parâmetros do nosso modelo de rede neural. Depois, partimos para a construção de um grafo TensorFlow. No grafo, primeiro adicionamos as variáveis das matrizes de parâmetros $\\pmb{W}$. Em vez de concatenarmos uma uma coluna de $\\pmb{1}$ aos inputs de cada camada, vamos adicionar um vetor de vieses $\\pmb{b}$. Uma vez criadas as variáveis, vamos encadear transformações lineares com não linearidades por duas camadas. Por fim, passamos o output da segunda camada para um modelo de regressão logística, ao qual chamaremos de camada de output. Como esse é um problema de classificação, vamos utilizar a função custo de entropia cruzada, que será minimizada com gradiente descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# definindo constantes\n",
    "lr = 0.01 # taxa de aprendizado\n",
    "n_iter = 4000 # número de iterações de treino\n",
    "batch_size = 128 # qtd de imagens no mini-lote (para GDE)\n",
    "n_inputs = 28 * 28 # número de variáveis (píxeis)\n",
    "n_l1 = 512 # número de neurônios da primeira camada\n",
    "n_l2 = 512 # número de neurônios da segunda camada\n",
    "n_outputs = 10 # número classes (dígitos)\n",
    "\n",
    "graph = tf.Graph() # cria um grafo\n",
    "with graph.as_default(): # abre o grafo para colocar nós\n",
    "    \n",
    "    # adiciona as variáveis da primeira camada ao grafo\n",
    "    W1 = tf.Variable(tf.truncated_normal([n_inputs, n_l1]), name='Weight_1')\n",
    "    b1 = tf.Variable(tf.zeros([n_l1]), name='bias_1')\n",
    "    \n",
    "    # adiciona as variáveis da segunda camada ao grafo\n",
    "    W2 = tf.Variable(tf.truncated_normal([n_l1, n_l2]), name='Weight_2')\n",
    "    b2 = tf.Variable(tf.zeros([n_l2]), name='bias_2')\n",
    "    \n",
    "    # adiciona as variáveis da camada de saída (ou modelo linear) grafo\n",
    "    Wo = tf.Variable(tf.truncated_normal([n_l2, n_outputs]), name='Weight_o')\n",
    "    bo = tf.Variable(tf.zeros([n_outputs]), name='bias_o')\n",
    "\n",
    "    ############################################\n",
    "    # Monta o modelo de rede neural artificial #\n",
    "    ############################################\n",
    "\n",
    "    # Camadas de Inputs\n",
    "    x_input = tf.placeholder(tf.float32, [None, n_inputs], name='X_input')\n",
    "    y_input = tf.placeholder(tf.float32, [None, n_outputs], name='y_input')\n",
    "\n",
    "    # Camada 1\n",
    "    l1 = tf.nn.relu(tf.matmul(x_input, W1) + b1, name='layer_1')\n",
    "    \n",
    "    # Camada 2\n",
    "    l2 = tf.nn.relu(tf.matmul(l1, W2) + b2, name='layer_2')\n",
    "\n",
    "    # Camada de output\n",
    "    logits = tf.add(tf.matmul(l2, Wo), bo, name='output_layer')\n",
    "    y_hat = tf.nn.softmax(logits) # converte scorer em probabilidades\n",
    "    \n",
    "    # função objetivo\n",
    "    error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_input, logits=logits, name='error'))\n",
    "    \n",
    "    # otimizador\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(error)\n",
    "\n",
    "    # inicializador\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # para salvar o modelo treinado\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Vamos agora, parte por parte entender o que foi feito acima. Dentro do grafo, primeiro definimos as variáveis. `W1` são os pesos da primeira camada. No nosso modelo, nós vamos multiplicar os dados com essa matriz, por isso ela tem o mesmo número de linhas que o número de variáveis nos dados. Além disso, o número de colunas dessa matriz definirá o número de neurônios da primeira camada da rede neural. Seja $z_1$ os neurônios da primeira camada, temos:\n",
    "\n",
    "$$\n",
    "\\phi \\Bigg( \\quad\n",
    "\\begin{bmatrix}\n",
    "x_{11} & ... & x_{1d} \\\\\n",
    "x_{21} & ... & x_{2d} \\\\\n",
    "\\vdots & \\vdots& \\vdots & \\vdots \\\\\n",
    "x_{n1} & ... & x_{nd} \\\\\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "w_{11} & ... & w_{1m} \\\\\n",
    "w_{21} & ... & w_{2m} \\\\\n",
    "\\vdots & \\vdots& \\vdots & \\vdots \\\\\n",
    "w_{d1} & ... & w_{dm} \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{d} \\\\\n",
    "\\end{bmatrix} \\quad \\Bigg)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_{11} \\\\\n",
    "z_{12} \\\\\n",
    "\\vdots \\\\\n",
    "z_{1n} \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Se você lembrar do [algoritmo de regressão linear](https://matheusfacure.github.io/2017/02/15/MQO-formula-analitica/), poderá perceber que, antes da não linearidade, a **multiplicação da matriz de dados por uma coluna da matriz de parâmetros é exatamente uma regressão linear**. Assim, vemos que **uma rede neural nada mais é do que várias regressões lineares seguidas de não linearidades**. É simples assim, por isso estou enfatizando isso. A próxima camada é análoga a primeira: nós multiplicamos inputs por uma matriz de parâmetros `W2`, adicionamos `b2` e aplicamos a não linearidade ReLU. As únicas diferenças entre a primeira e a segunda camada é que (1) agora o input não são mais os dados, mas os outputs da primeira camada, e que (2) a quantidade de neurônios (colunas de `W2`) é diferente. Como a atividade nos neurônios da primeira camada serão os inputs da segunda camada, a matriz de parâmetros dessa camada, `W2`, terá o mesmo número de linhas que os a quantidade de neurônios da primeira camada; o número de colunas de `W2` definirá a quantidade de neurônios da segunda camada. Finalmente, nós passamos o output da segunda camada para um modelo linear, nesse caso, uma regressão logística. Para isso, primeiro usamos uma transformação linear: `tf.add(tf.matmul(l2, Wo), bo, name='output_layer')`. Essa operação gera uma pontuação para cada classe/dígito, que geralmente é chamada de *logit*. Note que não usamos a não linearidade aqui. Em vez disso, passamos os *logits* direto para uma função de achatamento softmax, que converte a pontuação em uma probabilidade válida (às vezes chamada *probit*), isto é, de forma que a soma da probabilidade de cada dígito resulte em 1. Isso conclui nosso modelo.\n",
    "\n",
    "A seguir, nós definimos a função custo com `tf.nn.softmax_cross_entropy_with_logits()`. Essa função com um nome enorme faz duas coisas. Primeiro, converte os *logits* em probabilidades aplicando a função softmax e depois compara a previsão com o a classe real e retorna a função custo de entropia cruzada. Mas por que usar de novo a função softmax se já havíamos feito isso antes? Fazemos isso por simples estabilidade computacional. Usar entropia cruzada seguido de softmax podem resultar em números com muitas casas decimais ou muito grandes, coisas que um computador não consegue representar bem. O TensorFlow tem então essa função `tf.nn.softmax_cross_entropy_with_logits()` para realizar de forma estável uma tranformação softmax seguida do cálculo da entropia cruzada. Tome **muito cuidado** para não passar o tensor `y_hat` de probabilidades para `tf.nn.softmax_cross_entropy_with_logits()`. `y_hat` Já passou pela função softmax e passar esse tensor de novo por ela é problemático. A rede neural ainda irá treinar sem problemas, mas a performance será drasticamente reduzida e a convergência tomará muito mais tempo. Por isso, é difícil pegar esse *bug* e acabamos pensando que o modelo não é bom, quando na verdade erramos na especificação da função custo.\n",
    "\n",
    "O resto do grafo não é novo. Novamente, nós criamos um otimizador para minimizar o erro, um nó para inicializar as variáveis e um *saver* para salvar o modelo treinado.\n",
    "\n",
    "## Fase de execução\n",
    "\n",
    "A faze de execução pode ser reutilizada do [tutorial de TensorFlow](https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/) quase sem alteração. Como essa base de dados é muito grande, nós precisamos usar gradiente descendente estocástico (GDE) em vez de gradiente descendente normal. A diferença é explicada [neste tutorial](https://matheusfacure.github.io/2017/02/20/MQO-Gradiente-Descendente/#Gradiente-descendente-estocástico), mas, em poucas palavras, gradiente descendente realiza iterações mais precisas, o tempo de cada iteração aumenta com o tamanho da base de dados, tornando-se proibitivo para bases grades demais. Por outro lado, o tempo de uma iteração de treinamento de GDE **não** aumenta com o tamanho da base de dados, mas com o tamanho de um mini-lote de dados (que definimos acima). O preço que pagamos é um iteração menos precisa quanto menor for o mini-lote. Na pratica, a convergência é muito mais rápida com GDE.\n",
    "\n",
    "Nós também vamos calcular a acurácia de validação de tempos em tempos (1000 iterações). Para isso, é útil definir uma função que calcula a acurácia a partir do vetor de probabilidade de cada dígito. Para isso, vamos achar qual a posição de maior probabilidade no vetor. Isso nos dará o dígito previsto. Depois vamos comparar os dígitos previstos com os verdadeiros. Nós tiramos a média dos acerto e multiplicamos por 100 para ter a percentagem de acertos. Também salvaremos os parâmetros do modelo  cada 1000 iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro de treino na iteração 0: 2903.53\n",
      "Erro de validação na iteração 0: 1940.68\n",
      "Acurácia de validação na iteração 0: 11.52\n",
      "\n",
      "Erro de treino na iteração 1000: 12.85\n",
      "Erro de validação na iteração 1000: 6.11\n",
      "Acurácia de validação na iteração 1000: 97.46\n",
      "\n",
      "Erro de treino na iteração 2000: 3.83\n",
      "Erro de validação na iteração 2000: 12.35\n",
      "Acurácia de validação na iteração 2000: 95.31\n",
      "\n",
      "Erro de treino na iteração 3000: 6.29\n",
      "Erro de validação na iteração 3000: 6.11\n",
      "Acurácia de validação na iteração 3000: 97.85\n",
      "\n",
      "Erro de treino na iteração 4000: 1.32\n",
      "Erro de validação na iteração 4000: 8.18\n",
      "Acurácia de validação na iteração 4000: 96.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred_y, true_y):\n",
    "    '''Compara dois vetores one-hot para produzir a acurácia'''\n",
    "\n",
    "    pred_labels = np.argmax(pred_y, 1) # acha o dígito de maior prob. prevista\n",
    "    true_labels = np.argmax(true_y, 1) # acha o dígito verdadeiro\n",
    "    \n",
    "    return (pred_labels == true_labels).mean() * 100 # compara ambos\n",
    "\n",
    "\n",
    "# abrimos a sessão tf\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    init.run() # iniciamos as variáveis\n",
    "    \n",
    "    # loop de treinamento\n",
    "    for step in range(n_iter+1):\n",
    "\n",
    "        # cria os mini-lotes\n",
    "        x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "\n",
    "        # cria um feed_dict\n",
    "        feed_dict = {x_input: x_batch, y_input: y_batch}\n",
    "\n",
    "        # executa uma iteração de treino e calcula o erro\n",
    "        l, _ = sess.run([error, optimizer], feed_dict=feed_dict)\n",
    "            \n",
    "        # mostra o progresso a cada 1000 iterações\n",
    "        if step % 1000 == 0:\n",
    "            \n",
    "            x_valid, y_valid = data.validation.next_batch(512) # pega alguns dados de validação\n",
    "            val_dict = {x_input: x_valid, y_input: y_valid} # monta o feed_dict\n",
    "            error_np, probs = sess.run([error, y_hat], feed_dict=val_dict) # calcula probabilidades e erro \n",
    "            \n",
    "            print('Erro de treino na iteração %d: %.2f' % (step, l))\n",
    "            print('Erro de validação na iteração %d: %.2f' % (step, error_np))\n",
    "            print('Acurácia de validação na iteração %d: %.2f\\n' % (step, accuracy(probs, y_valid)))\n",
    "\n",
    "            saver.save(sess, \"./tmp/deep_ann.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Para calcular a acurácia, usamos `np.argmax()`, primeiro convertemos os vetores de probabilidades e o vetor *one-hot* nos dígitos que eles representam. Por exemplo, no caso do vetor que representa um 7 (`[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]`), `np.argmax()` retorna `7`, já que essa é a posição do maior número do vetor.  Outro detalhe importante é passar como segundo argumento para `np.argmax()` a dimensão para computar o máximo. No nosso caso, temos uma matriz de vetores de probabilidade empilhados. Essa matriz é do formato `[n_observações, n_digitos]` e nós queremos o máximo relativo a segunda dimensão. Assim, passamos `1` (a segunda dimensão, lembre-se de que a contagem começa em 0) para `np.argmax()` e obtemos um vetor com os dígitos previstos, no formato `[n_observações, 1]`.\n",
    "\n",
    "Quanto a fase de execução em sí, a única novidade quanto ao [tutorial passado](https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/) é que não passamos todos os dados para uma iteração de otimização, mas apenas um mini-lote de dados. Por conveniência, o TensorFlow envolveu os dados em um objeto que tem um método `.train.next_batch()` que nos dá o próximo mini-lote nos dados. Em outros casos, nós precisamos montar os mini-lotes na mão, mas isso é bastante simples (você pode conferir como fazer isso no [exercício que propus](https://github.com/matheusfacure/Tutoriais-de-AM/blob/master/Redes%20Neurais%20Artificiais/Tutorial%20de%20TensorFlow.ipynb) no tutorial de [TensorFlow Essencial](https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/).\n",
    "\n",
    "Com esse código e algumas poucas (4000) iterações de treino já conseguimos prever com mais de 96% de acurácia (de validção), qual dígito está representado em cada imagem (os resultados podem variar um pouco a cada execução do programa). Isso pode parecer bom, mas na verdade é uma performance bem irrisória para uma rede neural, nessa base de dados. Mais para frente, vamos ver como melhorar esses resultados.\n",
    "\n",
    "Antes de prosseguir, vale a pena chamar a atenção para alguns **erros e bug comuns** que podem aparecer. Em primeiro lugar, note como chamamos de `error_np` o erro de validação calculado a cada 1000 iterações. Fizemos isso pois a variável `error` já se referia ao nó de entropia cruzada no grafo TensorFlow. Usar a mesma variável em Python para se referir a essas duas coisas resultará em erros nem sempre fáceis de entender, por isso tome cuidado com o nome das suas variáveis! Um outro erro comum é passar dados no formato diferente dos *placeholders*. Para resolver isso, eu recomendo sempre verificar o formato dos dados com algo como `print(x_batch.shape)`.\n",
    "\n",
    "Agora que temos nosso modelo treinado e salvo, podemos restaurá-lo para fazer previsões. A seguir, vamos avaliar a performance da nossa rede neural em 5000 exemplos do set de teste. Se seu computado tem RAM o suficiente, sinta-se a vontade para usar o set de teste todo para avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/deep_ann.ckpt\n",
      "\n",
      "Acurácia de teste: 97.12\n"
     ]
    }
   ],
   "source": [
    "# novamente, abrimos a sessão tf\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    # restauramos o valor das variáveis \n",
    "    saver.restore(sess, \"./tmp/deep_ann.ckpt\", )\n",
    "    \n",
    "    x_test, y_test = data.test.next_batch(5000)\n",
    "    \n",
    "    # rodamos o nó de previsão no grafo\n",
    "    feed_dict = {x_input: x_test}\n",
    "    probs = y_hat.eval(feed_dict={x_input: x_test}) # calcula as probabilidades\n",
    "    \n",
    "    print('\\nAcurácia de teste: %.2f' % accuracy(probs, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tudo o que fizemos acima parece muito coisa, mas fizemos apenas poucas mudanças no código desenvolvido no tutorial de [TensorFlow Essencial](https://matheusfacure.github.io/2017/05/12/tensorflow-essencial/). Para entender melhor o que fizemos, eu **recomendo fortemente** que você copie o código de lá e tente modificá-lo para rodar essa rede neural.\n",
    "\n",
    "## Simplificando o código TensorFlow\n",
    "\n",
    "O programa desenvolvido usa as funcionalidades de mais baixo nível do TensorFlow e tem a vantagem de ser extremamente flexível. No entanto, quando só queremos montar uma simples rede neural profunda, o método que vimos é desnecessariamente longo. Por exemplo, por que precisamos definir as variáveis de cada camada?? Não parece óbvio que ao criar uma camada da rede neural as variáveis já deveriam ser criadas junto?? Felizmente, o TensorFlow dispõe de uma função que serve exatamente para isso: `tf.contrib.layers.fully_connected()`. É só passar para essa função os dados de entrada, a quantidade de neurônios e pronto, a mágica acontece. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "new_graph = tf.Graph()\n",
    "with new_graph.as_default():\n",
    "    \n",
    "    # Camadas de Inputs\n",
    "    x_input = tf.placeholder(tf.float32, [None, n_inputs], name='X_input')\n",
    "    y_input = tf.placeholder(tf.float32, [None, n_outputs], name='y_input')\n",
    "    \n",
    "    l1 = fully_connected(x_input, n_l1, scope=\"layer_1\") # camada 1\n",
    "    l2 = fully_connected(l1, n_l2, scope=\"layer_2\") # camada 2\n",
    "    \n",
    "    # camada de saída\n",
    "    logits = fully_connected(l2, n_outputs, activation_fn=None, scope=\"output_layer\")\n",
    "    y_hat = tf.nn.softmax(logits) # converte scorer em probabilidades\n",
    "    \n",
    "    # erro\n",
    "    error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_input, logits=logits, name='error'))\n",
    "    \n",
    "    # otimizador\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(error)\n",
    "\n",
    "    # inicializador\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # para salvar o modelo treinado\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Como padrão, a função de ativação de `fully_connected()` é a ReLU, por isso, só alteramos esse argumento na camada de saída, onde não queremos nenhuma função de ativação. A função `fully_connected()` facilita muito na implementação de redes neurais. Com ela, não precisamos definir variáveis e o código fica bem mais limpo. Além disso, várias funcionalidades estão implementadas em `fully_connected()`, como formas melhores de inicializar os parâmetros, regularização, e normalização. Isso talvez não faça muito sentido ainda, mas mais para frente veremos como melhorar a convergência das redes neurais com essas ferramentas. Eu recomendo fortemente que você leia a [documentação de `fully_connected()`](`fully_connected()`).\n",
    "\n",
    "A fase de execução desse do grafo simplificado acima é exatamente a mesma que mostramos antes. Você pode simplesmente copiar e tudo funcionará exatamente como antes. Só tome cuidado para mudar o nome do grafo que usaremos na sessão com `with tf.Session(graph=new_graph) as sess:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro de treino na iteração 0: 2.27\n",
      "Erro de validação na iteração 0: 3.07\n",
      "Acurácia de validação na iteração 0: 42.77\n",
      "\n",
      "Erro de treino na iteração 1000: 0.24\n",
      "Erro de validação na iteração 1000: 0.09\n",
      "Acurácia de validação na iteração 1000: 96.48\n",
      "\n",
      "Erro de treino na iteração 2000: 0.06\n",
      "Erro de validação na iteração 2000: 0.13\n",
      "Acurácia de validação na iteração 2000: 96.88\n",
      "\n",
      "Erro de treino na iteração 3000: 0.06\n",
      "Erro de validação na iteração 3000: 0.05\n",
      "Acurácia de validação na iteração 3000: 98.44\n",
      "\n",
      "Erro de treino na iteração 4000: 0.03\n",
      "Erro de validação na iteração 4000: 0.18\n",
      "Acurácia de validação na iteração 4000: 97.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calcula quantas iterações de treino por época\n",
    "def accuracy(pred_y, true_y):\n",
    "    '''Compara dois vetores one-hot para produzir a acurácia'''\n",
    "\n",
    "    pred_labels = np.argmax(pred_y, 1) # acha o dígito de maior prob. prevista\n",
    "    true_labels = np.argmax(true_y, 1) # acha o dígito verdadeiro\n",
    "    \n",
    "    return (pred_labels == true_labels).mean() * 100 # compara ambos\n",
    "\n",
    "\n",
    "# abrimos a sessão tf\n",
    "with tf.Session(graph=new_graph) as sess:\n",
    "    init.run() # iniciamos as variáveis\n",
    "    \n",
    "    # loop de treinamento\n",
    "    for step in range(n_iter+1):\n",
    "\n",
    "        # cria os mini-lotes\n",
    "        x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "\n",
    "        # cria um feed_dict\n",
    "        feed_dict = {x_input: x_batch, y_input: y_batch}\n",
    "\n",
    "        # executa uma iteração de treino e calcula o erro\n",
    "        l, _ = sess.run([error, optimizer], feed_dict=feed_dict)\n",
    "            \n",
    "        # mostra o progresso a cada 1000 iterações\n",
    "        if step % 1000 == 0:\n",
    "            \n",
    "            x_valid, y_valid = data.validation.next_batch(512) # pega alguns dados de validação\n",
    "            val_dict = {x_input: x_valid, y_input: y_valid} # monta o feed_dict\n",
    "            error_np, probs = sess.run([error, y_hat], feed_dict=val_dict) # calcula probabilidades e erro \n",
    "            \n",
    "            print('Erro de treino na iteração %d: %.2f' % (step, l))\n",
    "            print('Erro de validação na iteração %d: %.2f' % (step, error_np))\n",
    "            print('Acurácia de validação na iteração %d: %.2f\\n' % (step, accuracy(probs, y_valid)))\n",
    "\n",
    "            saver.save(sess, \"./tmp/deep_ann.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "No caso de redes neurais tão simples como essa nossa, podemos simplificar ainda mais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': None, '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5351c21908>, '_num_worker_replicas': 0, '_save_summary_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_task_type': None, '_tf_random_seed': None, '_task_id': 0, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpilauguh9\n",
      "WARNING:tensorflow:From <ipython-input-37-074c5f8c0ed1>:16: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-37-074c5f8c0ed1>:16: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-37-074c5f8c0ed1>:16: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpilauguh9/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.35878, step = 1\n",
      "INFO:tensorflow:global_step/sec: 37.0067\n",
      "INFO:tensorflow:loss = 0.19755, step = 101 (2.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.6967\n",
      "INFO:tensorflow:loss = 0.111026, step = 201 (2.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.9511\n",
      "INFO:tensorflow:loss = 0.0797299, step = 301 (2.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.814\n",
      "INFO:tensorflow:loss = 0.160103, step = 401 (2.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7418\n",
      "INFO:tensorflow:loss = 0.17806, step = 501 (2.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7872\n",
      "INFO:tensorflow:loss = 0.0803717, step = 601 (2.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.3077\n",
      "INFO:tensorflow:loss = 0.0935697, step = 701 (2.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4244\n",
      "INFO:tensorflow:loss = 0.289389, step = 801 (2.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.9141\n",
      "INFO:tensorflow:loss = 0.104132, step = 901 (2.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.8831\n",
      "INFO:tensorflow:loss = 0.207934, step = 1001 (2.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5424\n",
      "INFO:tensorflow:loss = 0.19267, step = 1101 (2.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.2316\n",
      "INFO:tensorflow:loss = 0.0570312, step = 1201 (2.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.6765\n",
      "INFO:tensorflow:loss = 0.100099, step = 1301 (2.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.9761\n",
      "INFO:tensorflow:loss = 0.0465638, step = 1401 (2.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7231\n",
      "INFO:tensorflow:loss = 0.0940935, step = 1501 (2.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.9915\n",
      "INFO:tensorflow:loss = 0.183063, step = 1601 (2.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.0174\n",
      "INFO:tensorflow:loss = 0.21403, step = 1701 (2.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.0982\n",
      "INFO:tensorflow:loss = 0.0865188, step = 1801 (2.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7492\n",
      "INFO:tensorflow:loss = 0.0341742, step = 1901 (2.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4528\n",
      "INFO:tensorflow:loss = 0.121428, step = 2001 (2.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7187\n",
      "INFO:tensorflow:loss = 0.0723809, step = 2101 (2.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.1512\n",
      "INFO:tensorflow:loss = 0.141982, step = 2201 (2.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.303\n",
      "INFO:tensorflow:loss = 0.06337, step = 2301 (2.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.3992\n",
      "INFO:tensorflow:loss = 0.0541582, step = 2401 (2.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.9061\n",
      "INFO:tensorflow:loss = 0.0660047, step = 2501 (2.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4077\n",
      "INFO:tensorflow:loss = 0.049908, step = 2601 (2.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4508\n",
      "INFO:tensorflow:loss = 0.115032, step = 2701 (2.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.577\n",
      "INFO:tensorflow:loss = 0.0447454, step = 2801 (2.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.6639\n",
      "INFO:tensorflow:loss = 0.0751914, step = 2901 (2.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2031\n",
      "INFO:tensorflow:loss = 0.0381775, step = 3001 (2.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5022\n",
      "INFO:tensorflow:loss = 0.0375767, step = 3101 (2.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5103\n",
      "INFO:tensorflow:loss = 0.352349, step = 3201 (2.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.6475\n",
      "INFO:tensorflow:loss = 0.226737, step = 3301 (2.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0599\n",
      "INFO:tensorflow:loss = 0.126144, step = 3401 (2.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.8821\n",
      "INFO:tensorflow:loss = 0.109885, step = 3501 (2.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7064\n",
      "INFO:tensorflow:loss = 0.303826, step = 3601 (2.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4757\n",
      "INFO:tensorflow:loss = 0.0895393, step = 3701 (2.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7242\n",
      "INFO:tensorflow:loss = 0.0595309, step = 3801 (2.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.9064\n",
      "INFO:tensorflow:loss = 0.16301, step = 3901 (2.229 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tmpilauguh9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.04776.\n",
      "WARNING:tensorflow:From <ipython-input-37-074c5f8c0ed1>:19: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-37-074c5f8c0ed1>:19: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-16-16:39:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpilauguh9/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-16-16:39:14\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.9671, global_step = 4000, loss = 0.155081\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.96710002, 'global_step': 4000, 'loss': 0.15508126}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = input_data.read_data_sets(\"tmp/\", one_hot=False) # carrega os dados já formatados\n",
    "\n",
    "x_input = tf.contrib.learn.infer_real_valued_columns_from_input(data.train.images)\n",
    "\n",
    "deep_ann = tf.contrib.learn.DNNClassifier(hidden_units = [n_l1, n_l2], # qtd de neurônios por camada\n",
    "                                         feature_columns = x_input, # var. independentes\n",
    "                                         n_classes = n_outputs, # número de classes (10)\n",
    "                                         activation_fn = tf.nn.relu, # função de ativação das camadas\n",
    "                                         optimizer = tf.train.AdamOptimizer(learning_rate=lr)) # otimizador \n",
    "\n",
    "deep_ann.fit(x=data.train.images.astype(np.float32), # conversão de tipo\n",
    "            y=data.train.labels.astype(np.int64), # conversão de tipo\n",
    "            batch_size=128, # tamanho do mini-lote\n",
    "            steps=4000) # iterações de treino\n",
    "\n",
    "deep_ann.evaluate(data.test.images.astype(np.float32), # variáveis independentes\n",
    "                  data.test.labels.astype(np.int64)) # variáveis dependentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ok... Esse código é extremamente abstrato. Em construímos uma rede neural em uma linha em outra, a treinamos. Vamos linha por linha detalhar o que está acontecendo. Nós primeiro definimos os inputs com `tf.contrib.learn.infer_real_valued_columns_from_input()`. O argumento dessa função são os dados de treino com as variáveis independentes. Nesse caso, `data.train.images`. Em seguida, criamos um classificador com `tf.contrib.learn.DNNClassifier()`, que é um envólucro de alto nível para abstrair todo o processo complicado de construção de uma rede neural. Os argumentos são autoexplicativos. Depois usamos o método `.fit()` desse classificador. A única complicação aqui é reformatar os dados. Como variável independente, `.fit()` aceita apenas o tipo numérico `float32`. As variáveis dependentes $y$ devem ser do tipo `float64`, por isso realizamos essas conversões. Além disso, a variável dependente $y$ não pode ser um vetor *one-hot*, mas um vetor de **índices representado classes**. Por isso, recarregamos os dados usando agora `one_hot=False`. No treinamento, usamos mini-lotes de com 128 amostrar e treinamos o modelo por 4000 iterações. Finalmente, usamos passamos ao método `.evaluate()` os dados e as classes de teste para avaliar o modelo. \n",
    "\n",
    "Uma aviso final que precisa ser dado é que o módulo `contrib` é um lugar de experimentação e pode mudar drasticamente de versão para versão do TensorFlow. Eu particularmente não gosto muito desse módulo. Ele abstrai muito do controle que gosto de ter ao construir as redes neurais. Porém, para aplicações bem simples, acredito que ele possa ser útil."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
